{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Ciência dos Dados - PROJETO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### *Bruno Kaczelnik, Guilherme Lotaif, Renato Tajima, Thiago Verardo*\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Airbnb nas maiores cidades americanas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 1. Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Neste Projeto será feita uma análise dos dados que possuimos de Airbnb nos Estados Unidos, e a partir dos dados que julgarmos pertinentes ao nosso estudo. Serão usados diferentes **métodos de predição** para descobrir`o preço de um aluguel dependendo das características fornecidas`, após usarmos os diferentes métodos, vamos comparar os resultados de cada método, finalmente poderemos concluir o projeto..\n",
    "\n",
    "   Um pouco mais sobre a plataforma digital Airbnb: Ela é utilizada para efetuar o aluguel de uma casa ou apartamento de outros usuários da própria plataforma. Com anúncios em 192 países, podemos concluir que é uma plataforma é bem grande, somente nos Estados Unidos existem aproximadamente 600.000 possiveis locais para aluguel. Com tantas opções, a escolha que o usuário faz quanto ao local é feita baseada nas **informações fornecidas pelo propretario**, tais informações podem variar desde quantos banheiros a residência possui, até se ela possui acesso a uma rede Wifi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fonte do dataset:** www.kaggle.com/rudymizrahi/airbnb-listings-in-major-us-cities-deloitte-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Minerando dados e características do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset que vamos utilizar nesse projeto possui diversas colunas com informações dos Airbnb nos Estados Unidos, portannto temos que percorrer todas essas colunas para fazer uma limpeza, e deixar somente as informações que serão pertinentes a nossa análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importando as bibliotecas que serão utilizadas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando bibliotecas:\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm,probplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "/Users/guilherme/Downloads/Projeto-3-CDD---DPA-master\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importado o arquivo de treinamento:\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Dataframe possui 74111 linhas por 29 colunas.\n"
     ]
    }
   ],
   "source": [
    "#Análisando o tamanho do dataframe de treino:\n",
    "linhas, colunas = df.shape\n",
    "print(\"O Dataframe possui {0} linhas por {1} colunas.\".format(linhas, colunas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "#### Limpando o dataframe de treino para ser análisado:\n",
    "Esta etapa consiste em uma preparação do dataframe para facilitar a análise no mesmo, assim evitando ocorrências de complicações ou erros que atrapalhem futuramento os nosssos classificadores. Portanto iremos limpar os titulos de cada coluna, vamos remover os valores nulos de cada categoria, assim como colunas desnecessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo os espaços em branco dos nomes das colunas:\n",
    "df.columns = [espaços.strip() for espaços in df.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando as datas do dataframe para o formato correto:\n",
    "df[\"host_since\"] = pd.to_datetime(df[\"host_since\"], errors='coerce')\n",
    "df[\"last_review\"] = pd.to_datetime(df[\"last_review\"], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo string de porcentagem para float:\n",
    "df['host_response_rate'] = df['host_response_rate'].str.rstrip('%').astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo colunas que não sao pertinentes ao estudo:\n",
    "df = df.drop([\"latitude\",\"longitude\",\"name\",\"thumbnail_url\",\"id\",\"description\",\"amenities\",\"zipcode\"],axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apagando valores nulos que podem causar problemas posteriores:\n",
    "df = df.dropna(axis=0, subset=['bathrooms','first_review','host_has_profile_pic','host_identity_verified',\n",
    "                               'host_response_rate','host_since','last_review','neighbourhood','review_scores_rating',\n",
    "                               'bedrooms','beds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corrigindo simplificação no arquivo:\n",
    "df.loc[(df[\"instant_bookable\"] == \"f\"),\"instant_bookable\"] = \"False\"\n",
    "df.loc[(df[\"instant_bookable\"] == \"t\"),\"instant_bookable\"] = \"True\"\n",
    "\n",
    "df.loc[(df[\"host_has_profile_pic\"] == \"f\"),\"host_has_profile_pic\"] = \"False\"\n",
    "df.loc[(df[\"host_has_profile_pic\"] == \"t\"),\"host_has_profile_pic\"] = \"True\"\n",
    "\n",
    "\n",
    "df.loc[(df[\"host_identity_verified\"] == \"f\"),\"host_identity_verified\"] = \"False\"\n",
    "df.loc[(df[\"host_identity_verified\"] == \"t\"),\"host_identity_verified\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>city</th>\n",
       "      <th>first_review</th>\n",
       "      <th>...</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_since</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>last_review</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.129899</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2017-08-05</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-09-23</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.976734</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-09-14</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>10</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_price property_type        room_type  accommodates  bathrooms  \\\n",
       "1   5.129899     Apartment  Entire home/apt             7        1.0   \n",
       "2   4.976734     Apartment  Entire home/apt             5        1.0   \n",
       "\n",
       "   bed_type cancellation_policy  cleaning_fee city first_review  ...   \\\n",
       "1  Real Bed              strict          True  NYC   2017-08-05  ...    \n",
       "2  Real Bed            moderate          True  NYC   2017-04-30  ...    \n",
       "\n",
       "  host_identity_verified host_response_rate  host_since instant_bookable  \\\n",
       "1                  False              100.0  2017-06-19             True   \n",
       "2                   True              100.0  2016-10-25             True   \n",
       "\n",
       "  last_review   neighbourhood number_of_reviews  review_scores_rating  \\\n",
       "1  2017-09-23  Hell's Kitchen                 6                  93.0   \n",
       "2  2017-09-14          Harlem                10                  92.0   \n",
       "\n",
       "   bedrooms  beds  \n",
       "1       3.0   3.0  \n",
       "2       1.0   3.0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "#### Transformando categorias qualiativas em quantiativas:\n",
    "\n",
    "O método usado para efetuar essa conversão é chamado de **One Hot Encoding**, que transforma variaveis categóricas em vetores binarios. Tal método transforma todas as variaveis em 0 menos a do item analisado, desse modo permitindo que sejam feitam análises em cima desse dados.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para chamar o get_dummies e remover a coluna base:\n",
    "def dummify(data, column_name):\n",
    "    df1 = data.copy()\n",
    "    df2 = pd.concat([df1.drop(column_name, axis=1), pd.get_dummies(data[column_name], prefix=column_name)], axis=1)\n",
    "    return df2\n",
    "\n",
    "#Transformando \"category\" em uma variável quantitativa:\n",
    "DF = dummify(df, \"property_type\")\n",
    "DF = dummify(DF, \"room_type\")\n",
    "DF = dummify(DF, \"bed_type\")\n",
    "DF = dummify(DF, \"cancellation_policy\")\n",
    "DF = dummify(DF, \"cleaning_fee\")\n",
    "DF = dummify(DF, \"city\")\n",
    "DF = dummify(DF, \"host_has_profile_pic\")\n",
    "DF = dummify(DF, \"host_identity_verified\")\n",
    "DF = dummify(DF, \"instant_bookable\")\n",
    "DF = dummify(DF, \"neighbourhood\")#Talvez tenha pouca influência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### - Análise descritiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após realizarmos o filtro, deve-se realizar uma análise exploratória dos dados, com o  objetivo de achar as váriaveis que mais influenciam no nosso objetivo e que assim possam nos ajudar a prever qual será a avaliação de um hotel aleatório. Ela será feita com o auxílio do pandas_profiling e seaborn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizandoo o pandas_profiling\n",
    "#df é o dataframe após o filtro\n",
    "pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Modelos de predição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adequando nosso dataframe para as predições:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = DF.drop([\"log_price\",\"host_since\",\"first_review\",\"last_review\"],axis=1)\n",
    "DF = DF.drop([\"host_since\",\"first_review\",\"last_review\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas necessárias:\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "RANDOM_SEED = 10\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividindo os dados do dataframe em teste e treino:\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pred, DF.log_price, test_size = 0.33, random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoder:**\n",
    "\n",
    "Alguns dos nossos dados estão classificados como continuos, temos que codifica-los da maneira correta para usar-mos os mesmos nos nossos modelos de predição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chamando o nosso Encoder:\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "\n",
    "#Vamos nos certificar do funcionamento do encoder usado:\n",
    "#print(training_scores_encoded)\n",
    "#print(utils.multiclass.type_of_target(y_train))\n",
    "#print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "#print(utils.multiclass.type_of_target(training_scores_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "...<br>\n",
    "<br>\n",
    "\n",
    "o `MODELO DE PREDIÇÃO PELA MÉDIA (Sem uso de variável explicativa)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.772880520973572"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.mean(DF.log_price)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "...<br>\n",
    "<br>\n",
    "\n",
    "o `MODELO DOS K VIZINHOS MAIS PRÓXIMOS (K-Nearest Neighbors Regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas necessárias para esse modelo:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-22895.873395466704\n"
     ]
    }
   ],
   "source": [
    "#Chamando o classificador:\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#Fazendo um fit nos dados de treino:\n",
    "knn.fit(X_train, training_scores_encoded)\n",
    "\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "#Descobrindo a acurácia do modelo de predição:\n",
    "print(r2_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "...<br>\n",
    "<br>\n",
    "\n",
    "o `MODELO DE REGRESSÃO LINEAR (Multiple Linear Regression)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas necessárias para esse modelo:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: -40811.686284267074\n"
     ]
    }
   ],
   "source": [
    "#Chamando o classificador:\n",
    "model = LogisticRegression()\n",
    "\n",
    "#Fazendo um fit nos dados de treino:\n",
    "model.fit(X_train, training_scores_encoded)\n",
    "\n",
    "CategoriasY_pred = model.predict(X_test)\n",
    "\n",
    "#Descobrindo a acurácia do modelo de predição:\n",
    "print('Acurácia: {}'.format(r2_score(y_test, CategoriasY_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "...<br>\n",
    "<br>\n",
    "\n",
    "o `MODELO DE ÁRVORES DE REGRESSÃO (Decision Tree Regression)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas necessárias para esse modelo:\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 é de -44639.32\n"
     ]
    }
   ],
   "source": [
    "#Chamando o classificador:\n",
    "clf = DecisionTreeClassifier(random_state = 100, max_depth=8, min_samples_leaf=4)\n",
    "\n",
    "#Fazendo um fit nos dados de treino:\n",
    "clf.fit(X_train, training_scores_encoded)   \n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#Descobrindo a acurácia do modelo de predição:\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 é de {:.2f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...<br>\n",
    "<br>\n",
    "\n",
    "<font color=red>o `MODELO RANDOM FOREST (Para comparação`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas necessárias para esse modelo:\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 é de: -42225.59\n"
     ]
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "\n",
    "x_logistica = np.linspace(-10, 10, 500)\n",
    "y_logistica = 1/(1 + np.exp(-x_logistica))\n",
    "\n",
    "#Chamando o RandomForestClassifier:\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "#Fazendo um fit nos dados de treino:\n",
    "model.fit(X_train, training_scores_encoded)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Descobrindo a acurácia do modelo de predição:\n",
    "print('R2 é de: {:.2f}'.format(r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## 4. Processo e estatísticas de validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Esse item depende dos resultados das modelagens anteriores! Organize-os aqui de forma clara!]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 5. Conclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 6. Referências bibliográficas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://www.mldata.io/tutorials/scikit_knn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://www.kaggle.com/pratsiuk/valueerror-unknown-label-type-continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
