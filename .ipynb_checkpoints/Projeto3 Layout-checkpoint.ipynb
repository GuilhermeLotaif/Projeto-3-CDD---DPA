{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Ciência dos Dados - PROJETO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### *Bruno Kaczelnik, Guilherme Lotaif, Renato Yasuo Chopard Tajima, Thiago Verardo*\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Airbnb nas maiores cidades americanas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 1. Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Neste Projeto será feita uma análise dos dados que possuimos de Airbnb nos Estados Unidos, e a partir dos dados que julgarmos pertinentes ao nosso estudo. Serão usados diferentes **métodos de predição** para descobrir`o preço de um aluguel dependendo das características fornecidas`, após usarmos os diferentes métodos, vamos comparar os resultados de cada método, finalmente poderemos concluir o projeto..\n",
    "\n",
    "   Um pouco mais sobre a plataforma digital Airbnb: Ela é utilizada para efetuar o aluguel de uma casa ou apartamento de outros usuários da própria plataforma. Com anúncios em 192 países, podemos concluir que é uma plataforma é bem grande, somente nos Estados Unidos existem aproximadamente 600.000 possiveis locais para aluguel. Com tantas opções, a escolha que o usuário faz quanto ao local é feita baseada nas **informações fornecidas pelo propretario**, tais informações podem variar desde quantos banheiros a residência possui, até se ela possui acesso a uma rede Wifi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fonte do dataset:** www.kaggle.com/rudymizrahi/airbnb-listings-in-major-us-cities-deloitte-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Minerando dados e características do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset que vamos utilizar nesse projeto possui diversas colunas com informações dos Airbnb nos Estados Unidos, portannto temos que percorrer todas essas colunas para fazer uma limpeza, e deixar somente as informações que serão pertinentes a nossa análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importando as bibliotecas que serão utilizadas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando bibliotecas:\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm,probplot\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importado o arquivo de treinamento:\n",
    "df_train = pd.read_csv('train.csv')\n",
    "\n",
    "#Importado o arquivo de treinamento:\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Análisando o tamanho do dataframe de treino:\n",
    "linhas, colunas = df_train.shape\n",
    "print(\"O Dataframe possui {0} linhas por {1} colunas.\".format(linhas, colunas))\n",
    "\n",
    "#Análisando o tamanho do dataframe teste:\n",
    "linhas, colunas = df_test.shape\n",
    "print(\"O Dataframe possui {0} linhas por {1} colunas.\".format(linhas, colunas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "#### Limpando o dataframe de treino para ser análisado:\n",
    "Esta etapa consiste em uma preparação do dataframe para facilitar a análise no mesmo, assim evitando ocorrências de complicações ou erros que atrapalhem futuramento os nosssos classificadores. Portanto iremos limpar os titulos de cada coluna, vamos remover os valores nulos de cada categoria, assim como colunas desnecessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo os espaços em branco dos nomes das colunas:\n",
    "df_train.columns = [espaços.strip() for espaços in df_train.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo colunas que não sao pertinentes ao estudo:\n",
    "df_train = df_train.drop([\"latitude\",\"longitude\",\"name\",\"thumbnail_url\",\"id\",\"description\"],axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apagando valores nulos que podem causar problemas posteriores:\n",
    "df_train = df_train.dropna(axis=0, subset=['bathrooms','first_review','host_has_profile_pic','host_identity_verified',\n",
    "                               'host_response_rate','host_since','last_review','neighbourhood','review_scores_rating',\n",
    "                               'zipcode','bedrooms','beds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corrigindo simplificação no arquivo:\n",
    "df_train.loc[(df_train[\"instant_bookable\"] == \"f\"),\"instant_bookable\"] = \"False\"\n",
    "df_train.loc[(df_train[\"instant_bookable\"] == \"t\"),\"instant_bookable\"] = \"True\"\n",
    "\n",
    "df_train.loc[(df_train[\"host_has_profile_pic\"] == \"f\"),\"host_has_profile_pic\"] = \"False\"\n",
    "df_train.loc[(df_train[\"host_has_profile_pic\"] == \"t\"),\"host_has_profile_pic\"] = \"True\"\n",
    "\n",
    "\n",
    "df_train.loc[(df_train[\"host_identity_verified\"] == \"f\"),\"host_identity_verified\"] = \"False\"\n",
    "df_train.loc[(df_train[\"host_identity_verified\"] == \"t\"),\"host_identity_verified\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "#### Limpando o dataframe de teste para ser análisado:\n",
    "Esta etapa consiste em uma preparação do dataframe para facilitar a análise no mesmo, assim evitando ocorrências de complicações ou erros que atrapalhem futuramento os nosssos classificadores. Portanto iremos limpar os titulos de cada coluna, vamos remover os valores nulos de cada categoria, assim como colunas desnecessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo os espaços em branco dos nomes das colunas:\n",
    "df_test.columns = [espaços.strip() for espaços in df_test.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo colunas que não sao pertinentes ao estudo:\n",
    "df_test = df_test.drop([\"latitude\",\"longitude\",\"name\",\"thumbnail_url\",\"id\",\"description\"],axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apagando valores nulos que podem causar problemas posteriores:\n",
    "df_test = df_test.dropna(axis=0, subset=['bathrooms','first_review','host_has_profile_pic','host_identity_verified',\n",
    "                               'host_response_rate','host_since','last_review','neighbourhood','review_scores_rating',\n",
    "                               'zipcode','bedrooms','beds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corrigindo simplificação no arquivo:\n",
    "df_test.loc[(df_test[\"instant_bookable\"] == \"f\"),\"instant_bookable\"] = \"False\"\n",
    "df_test.loc[(df_test[\"instant_bookable\"] == \"t\"),\"instant_bookable\"] = \"True\"\n",
    "\n",
    "df_test.loc[(df_test[\"host_has_profile_pic\"] == \"f\"),\"host_has_profile_pic\"] = \"False\"\n",
    "df_test.loc[(df_test[\"host_has_profile_pic\"] == \"t\"),\"host_has_profile_pic\"] = \"True\"\n",
    "\n",
    "\n",
    "df_test.loc[(df_test[\"host_identity_verified\"] == \"f\"),\"host_identity_verified\"] = \"False\"\n",
    "df_test.loc[(df_test[\"host_identity_verified\"] == \"t\"),\"host_identity_verified\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECAR DESCRIPTION\n",
    "\n",
    "#### Separando os atributos na coluna de características:\n",
    "<br>\n",
    "Para um melhor rendimento dos métodos de prdição, vamos separar cada atributo para que eles possam ser análisados e comparados de maneira unitária, e para isso vamos juntar todas palavras em listas para cada anúncio, e depois comparar não só os itens quanto o tamanho das listas também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#Criando uma lista para as palavras dos emails SPAM:\n",
    "dic_amenities = {}\n",
    "#Criando a variável contador para o total de palavras SPAM:\n",
    "contador_amenities = 0\n",
    "\n",
    "#Criando um loop para atribuir os emails SPAM a uma variável:\n",
    "for qualidades in df.amenities:\n",
    "    #Criando um loop para alocar as palavras de SPAM no dicionário:\n",
    "    for caracteristica in qualidades:\n",
    "        #print(caracteristica)\n",
    "        if caracteristica not in dic_amenities:\n",
    "            print(caracteristica)\n",
    "            dic_amenities[caracteristica] =1\n",
    "            contador_amenities +=1\n",
    "        else:\n",
    "            dic_amenities[caracteristica] +=1\n",
    "            contador_amenities +='''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### - Análise descritiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após realizarmos o filtro, deve-se realizar uma análise exploratória dos dados, com o  objetivo de achar as váriaveis que mais influenciam no nosso objetivo e que assim possam nos ajudar a prever qual será a avaliação de um hotel aleatório. Ela será feita com o auxílio do pandas_profiling e seaborn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizandoo o pandas_profiling\n",
    "#df é o dataframe após o filtro\n",
    "pandas_profiling.ProfileReport(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Modelos de predição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "o MODELO DE PREDIÇÃO PELA MÉDIA (Sem uso de variável explicativa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "o MODELO DOS K VIZINHOS MAIS PRÓXIMOS (K-Nearest Neighbors Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "o MODELO DE REGRESSÃO LINEAR (Multiple Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "o MODELO DE ÁRVORES DE REGRESSÃO (Decision Tree Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo colunas que não sao pertinentes ao estudo:\n",
    "df2 = df.drop([\"latitude\",\"longitude\",\"name\",\"thumbnail_url\",\"id\",\"description\"],axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividindo os dados do dataframe em teste e treino:\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1, df2['log_price'], test_size = 0.33, random_state = 0)                           \n",
    "\n",
    "#Chamando o classificador:\n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100, \n",
    "                                   max_depth=8, min_samples_leaf=4)\n",
    "#Fazendo um fit nos dados de treino:\n",
    "clf_gini.fit(X_train, y_train)   \n",
    "\n",
    "y_pred = clf_gini.predict(X_test)\n",
    "\n",
    "#Descobrindo a acurácia do classificador:\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "acc = acc*100\n",
    "print(\"A acurácia é de {:.2f}%\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>o MODELO DO RANDOM FOREST (Para comparação)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## 4. Processo e estatísticas de validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Esse item depende dos resultados das modelagens anteriores! Organize-os aqui de forma clara!]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 5. Conclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 6. Referências bibliográficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
